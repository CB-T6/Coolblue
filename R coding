#Coolblue

#Check for missing values 
apply(is.na(broadcasting_data[,]),2,sum) 
apply(is.na(traffic_data[,]),2,sum) # average session: 13,5% of missing values & 
                                    # bounces :49% of missing values . We delete variable "bounces"
                                              
#Converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))                                 
                        
#Deleting "bounces"
traffic_data <- subset(traffic_data, select = -c(bounces))
summary(traffic_data)                                   
                                   
#Convert into dates/time
traffic_data$date_time <- as.POSIXct(traffic_data$date_time)
broadcasting_data$date <- as.POSIXct(broadcasting_data$date)

#Factorize
traffic_data$medium <- as.factor(traffic_data$medium)
traffic_data$visit_source <- as.factor(traffic_data$visit_source)
traffic_data$page_category<-as.factor(traffic_data$page_category)
traffic_data$country<-as.factor(traffic_data$country)
broadcasting_data$operator <- as.factor(broadcasting_data$operator)
broadcasting_data$channel <- as.factor(broadcasting_data$channel)
broadcasting_data$position_in_break <- as.factor(broadcasting_data$position_in_break)
broadcasting_data$length_of_spot <- as.factor(broadcasting_data$length_of_spot)
broadcasting_data$program_before <- as.factor(broadcasting_data$program_before)
broadcasting_data$program_after <- as.factor(broadcasting_data$program_after)
broadcasting_data$program_category_before <- as.factor(broadcasting_data$program_category_before)
broadcasting_data$program_category_after <- as.factor(broadcasting_data$program_category_after)
broadcasting_data$product_category <- as.factor(broadcasting_data$product_category)
broadcasting_data$country <- as.factor(broadcasting_data$country)
 

#cleanup first
updated_traffic <- subset(traffic_data, visit_source!= "push notification")
traffic_data <- subset(updated_traffic, visit_source!= "other")

#Check for outliers
boxplot(broadcasting_data$gross_rating_point,xlab ="gross_rating_point")          # many  outliers, not gonna delete them, important for analysis
boxplot(traffic_data$avg_session_quality,xlab ="avg_session_quality")


#Descriptive Statistics
library(psych)
describe(broadcasting_data)
describe(traffic_data$avg_session_quality)
describe(traffic_data$visits_index)
                            

#find the mean 
mean(traffic_data$avg_session_quality, na.rm = TRUE)
apply(is.na(traffic_data[,]),2,sum) 
mean(traffic_data$avg_session_quality, na.rm = TRUE )


#converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))


#data exploration 
#Mean and variance for two numeric variables
traffic_data %>%
  summarise(median=median(avg_session_quality), variance=var(avg_session_quality))


traffic_data %>%
  summarise(median=median(visits_index), variance=var(visits_index))

traffic_data %>%
  summarise(mean=mean(visits_index), variance=var(visits_index))



range(traffic_data$visits_index)

min(traffic_data$avg_session_quality) #1
max(traffic_data$avg_session_quality) #96



(country_separation1 <- traffic_data %>%
  group_by(country) %>% 
  summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #useful

(country_separation2 <- traffic_data %>%
    group_by(country) %>% 
    summarise(mean=mean(visits_index), variance=var(visits_index))) #useful


#for now not helping, future?
(country_separation3 <- traffic_data %>%
    group_by(date_time) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

(country_separation3 <- traffic_data %>%
    group_by(date_time, country) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

table(traffic_data$medium, traffic_data$country)/length(traffic_data$medium)
table(traffic_data$page_category)/length(traffic_data$page_category)            
table(traffic_data$page_category, traffic_data$country) / length(traffic_data$country)          

#numeric variables
range(traffic_data$avg_session_quality)
range(traffic_data$visits_index) #maybe

#corr - must be numeric
cor(traffic_data$avg_session_quality, traffic_data$visits_index) #-0.005074682
cov(traffic_data$avg_session_quality, traffic_data$visits_index) #=variance, -0.001598219


plot(traffic_data$avg_session_quality, traffic_data$visits_index)

                                  
                                  
                                  
#DATA EXPLORATION FOR BROADCASTING 
plot(broadcasting_data$position_in_break, broadcasting_data$length_of_spot)
plot(broadcasting_data$gross_rating_point, broadcasting_data$position_in_break)

levels(broadcasting_data$position_in_break ) #to use


table(broadcasting_data$length_of_spot, broadcasting_data$country )
table(broadcasting_data$position_in_break, broadcasting_data$country)

#RELEVELS
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Before Last Position"] <- "98"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Any Other Position"] <- "0"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "First Position"] <- "1"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Last Position"] <- "99"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Second Position"] <- "2"
levels(broadcasting_data$position_in_break ) #to use


####create df for tables
broadtabledf <- broadcasting_data
####drop categories after top 5 for broadcast_data
library(tidyverse)
broadtabledf$program_category_before <- fct_lump_n(broadtabledf$program_category_before, n = 5)
broadtabledf$program_category_after <- fct_lump_n(broadtabledf$program_category_after, n = 5)
broadtabledf$position_in_break <- fct_lump_n(broadtabledf$position_in_break, n = 5)
##create tables
library(table1)
table1::table1(~position_in_break + length_of_spot + program_category_before + program_category_after | country, data = broadtabledf, topclass="Rtable1-zebra")
table1::table1(~visits_index + medium + visit_source + page_category | country, data = traffic_data, topclass="Rtable1-zebra")

##### merge for belgium with data.table package
BEtraffic2 <- as.data.table(BEtraffic)
BEbroad2 <- as.data.table(BEbroad)
library(data.table)
setkey(BEtraffic2, "date_time")
setkey(BEbroad2, "date_time")
two_minutes <- 2
BEcombined <- BEbroad2[BEtraffic2, roll = +two_minutes]


####first Dif in Dif model

broadcasting_data2 <- broadcasting_data
broadcasting_data2$date_time <- as.POSIXct(paste(broadcasting_data2$date, broadcasting_data2$time), format="%Y-%m-%d %H:%M:%S")
broadcasting_data2 <- broadcasting_data2 [,-3] # use this 2 times please to delete date and time old colmns
BEtraffic <- traffic_data %>% filter(country =="Belgium")
BEbroad <- broadcasting_data2 %>% filter(country =="Belgium")
NLtraffic <- traffic_data %>% filter(country =="Netherlands")
NLbroad <- broadcasting_data2 %>% filter(country =="Netherlands")
didtraffic <- traffic_data %>% filter(date_time >"2019-01-28" & date_time < "2019-04-15")
didtraffic$time = ifelse(didtraffic$date_time > "2019-01-28" & didtraffic$date_time < "2019-02-11" | 
                           didtraffic$date_time > "2019-04-08" & didtraffic$date_time < "2019-04-15", 0, 1)
didtraffic$treated = ifelse(didtraffic$country == "Netherlands", 1, 0)
didtraffic$did = didtraffic$time * didtraffic$treated

library(sjPlot)
library(sjmisc)
library(sjlabelled)
didreg1 = lm(log(visits_index) ~ treated + time + did + medium + visit_source + page_category + avg_session_quality, data = didtraffic)
summary(didreg1)
tab_model(didreg1)

############metric of dif of number of visits 10 min before and 10 min after
library(dplyr)
library(tidyverse)

traffic_datatest <-traffic_data
broadcasting_datatest <-broadcasting_data6
traffic_datatest$date_time <- as.numeric(traffic_data$date_time)
broadcasting_datatest$dateandtime <- as.numeric(broadcasting_data6$dateandtime)


NLtraffictest <- traffic_datatest %>% filter(country =="Netherlands")
NLbroadtest <- broadcasting_datatest %>% filter(country =="Netherlands")

BEtraffictest <- traffic_datatest %>% filter(country =="Belgium")
BEbroadtest <- broadcasting_datatest %>% filter(country =="Belgium")

NLbroadtest$twominbefore <- sapply(NLbroadtest$dateandtime, 
                                             function(x){ sum((x >= NLtraffictest$date_time) & (x - 600 <= NLtraffictest$date_time))
                                             })

BEbroadtest$twominbefore <- sapply(BEbroadtest$dateandtime, 
                                     function(x){ sum((x >= BEtraffictest$date_time) & (x - 600 <= BEtraffictest$date_time))
                                     })



NLbroadtest$twominafter <- sapply(NLbroadtest$dateandtime, 
                                   function(x){ sum((x <= NLtraffictest$date_time) & (x + 600 >= NLtraffictest$date_time))
                                   })

BEbroadtest$twominafter <- sapply(BEbroadtest$dateandtime, 
                                   function(x){ sum((x <= BEtraffictest$date_time) & (x + 600 >= BEtraffictest$date_time))
                                   })

NLbroadtest$ad_effect <- NLbroadtest$twominafter - NLbroadtest$twominbefore
BEbroadtest$ad_effect <- BEbroadtest$twominafter - BEbroadtest$twominbefore
 linearNL <- lm(NLbroadtest$ad_effect ~ NLbroadtest$operator + NLbroadtest$channel + NLbroadtest$position_in_break + NLbroadtest$length_of_spot + NLbroadtest$program_category_before + NLbroadtest$program_category_after
                + NLbroadtest$gross_rating_point + NLbroadtest$product_category + NLbroadtest$dateandtime)
summary(linearNL) 
#############end of try of metric

########adams SQL
---
title: "TEST"
author: "Adam Kinser"
date: "1/29/2021"
output: html_document
---
```{r}
broadcasting_data6 <- broadcasting_data
broadcasting_data6$dateandtime <- as.POSIXct(paste(broadcasting_data$date, broadcasting_data$time), format="%Y-%m-%d %H:%M:%S")
broadcasting_data6 <- broadcasting_data6 [,-3] # use this 2 times please to delete date and time old colmns
NLtrafficSQL <- NLtraffic
NLbroadSQL <- NLbroad
```

```{r setup, include=FALSE}

library(RSQLite) # use this package to create a temporary SQL database on your computer
library(DBI) # use this to write SQL chunks and write to your temporary database (DB)

db <- dbConnect(RSQLite::SQLite(), ":memory:") # store the db in your memory

knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_chunk$set(connection = "db") # set you db connection for the rmarkdown


table_ad_data <- Id(table = "ad_data") # name your ad data SQL table

DBI::dbWriteTable(conn = db, # database 
                  name = table_ad_data, # name of your table
                  value = NLbroad[], # what you are loading into the table
                  overwrite = T) # overwrite option will replace the data in the current ad_data table with the new load value. You can remove `overwrite` and use `append` if you want the new value to be added to existing data.

table_traffic <- Id(table = "traffic_data") 

DBI::dbWriteTable(conn = db,
                  name = table_traffic,
                  value = NLtraffic[],
                  overwrite = T)

```

# SQL code that you can add

After adding your R chunk be sure to change the `r` to `sql` in order write SQL. 

### Check first load
```{sql, connection = db}

select * from ad_data

```

### Check second load

Note: I have to wrap `Sepal.Length` with `` because it has a '.' in the column name. If you don't do this you will get an error. 
```{sql, connection = db}

select * from traffic_data join ad_data on date_time <= dateandtime

```

### Perform the join with datetime

In the below example I use cars column (speed) to represent your ad datetime and the iris column (Sepal.Length) to represent your traffic datetime. Be sure to add the `output.var` if you want to then use that data as a dataframe in the rest of the Rmarkdown. 
```{sql, connection = db, output.var = "combined2"}

SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index)
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime

```


```{r}
combined2
```


```{sql, connection = db, output.var = "NLSQL"}
WITH NL as 
(SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index) as indexmean
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime)


SELECT * FROM ad_data da INNER JOIN NL data
ON da.dateandtime=data.ad 

```

#######adams SQL
