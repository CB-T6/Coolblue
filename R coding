#Coolblue

#Check for missing values 
apply(is.na(broadcasting_data[,]),2,sum) 
apply(is.na(traffic_data[,]),2,sum) # average session: 13,5% of missing values & 
                                    # bounces :49% of missing values . We delete variable "bounces"
                                              
#Converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))                                 
                        
#Deleting "bounces"
traffic_data <- subset(traffic_data, select = -c(bounces))
summary(traffic_data)                                   
                                   
#Convert into dates/time
traffic_data$date_time <- as.POSIXct(traffic_data$date_time)
broadcasting_data$date <- as.POSIXct(broadcasting_data$date)

#Factorize
traffic_data$medium <- as.factor(traffic_data$medium)
traffic_data$visit_source <- as.factor(traffic_data$visit_source)
traffic_data$page_category<-as.factor(traffic_data$page_category)
traffic_data$country<-as.factor(traffic_data$country)
broadcasting_data$operator <- as.factor(broadcasting_data$operator)
broadcasting_data$channel <- as.factor(broadcasting_data$channel)
broadcasting_data$position_in_break <- as.factor(broadcasting_data$position_in_break)
broadcasting_data$length_of_spot <- as.factor(broadcasting_data$length_of_spot)
broadcasting_data$program_before <- as.factor(broadcasting_data$program_before)
broadcasting_data$program_after <- as.factor(broadcasting_data$program_after)
broadcasting_data$program_category_before <- as.factor(broadcasting_data$program_category_before)
broadcasting_data$program_category_after <- as.factor(broadcasting_data$program_category_after)
broadcasting_data$product_category <- as.factor(broadcasting_data$product_category)
broadcasting_data$country <- as.factor(broadcasting_data$country)
 

#cleanup first
updated_traffic <- subset(traffic_data, visit_source!= "push notification")
traffic_data <- subset(updated_traffic, visit_source!= "other")

#Check for outliers
boxplot(broadcasting_data$gross_rating_point,xlab ="gross_rating_point")          # many  outliers, not gonna delete them, important for analysis
boxplot(traffic_data$avg_session_quality,xlab ="avg_session_quality")


#Descriptive Statistics
library(psych)
describe(broadcasting_data)
describe(traffic_data$avg_session_quality)
describe(traffic_data$visits_index)
                            

#find the mean 
mean(traffic_data$avg_session_quality, na.rm = TRUE)
apply(is.na(traffic_data[,]),2,sum) 
mean(traffic_data$avg_session_quality, na.rm = TRUE )


#converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))


#data exploration 
#Mean and variance for two numeric variables
traffic_data %>%
  summarise(median=median(avg_session_quality), variance=var(avg_session_quality))


traffic_data %>%
  summarise(median=median(visits_index), variance=var(visits_index))

traffic_data %>%
  summarise(mean=mean(visits_index), variance=var(visits_index))



range(traffic_data$visits_index)

min(traffic_data$avg_session_quality) #1
max(traffic_data$avg_session_quality) #96



(country_separation1 <- traffic_data %>%
  group_by(country) %>% 
  summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #useful

(country_separation2 <- traffic_data %>%
    group_by(country) %>% 
    summarise(mean=mean(visits_index), variance=var(visits_index))) #useful


#for now not helping, future?
(country_separation3 <- traffic_data %>%
    group_by(date_time) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

(country_separation3 <- traffic_data %>%
    group_by(date_time, country) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

table(traffic_data$medium, traffic_data$country)/length(traffic_data$medium)
table(traffic_data$page_category)/length(traffic_data$page_category)            
table(traffic_data$page_category, traffic_data$country) / length(traffic_data$country)          

#numeric variables
range(traffic_data$avg_session_quality)
range(traffic_data$visits_index) #maybe

#corr - must be numeric
cor(traffic_data$avg_session_quality, traffic_data$visits_index) #-0.005074682
cov(traffic_data$avg_session_quality, traffic_data$visits_index) #=variance, -0.001598219


plot(traffic_data$avg_session_quality, traffic_data$visits_index)

                                  
                                  
                                  
#DATA EXPLORATION FOR BROADCASTING 
plot(broadcasting_data$position_in_break, broadcasting_data$length_of_spot)
plot(broadcasting_data$gross_rating_point, broadcasting_data$position_in_break)

levels(broadcasting_data$position_in_break ) #to use


table(broadcasting_data$length_of_spot, broadcasting_data$country )
table(broadcasting_data$position_in_break, broadcasting_data$country)

#RELEVELS
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Before Last Position"] <- "98"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Any Other Position"] <- "0"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "First Position"] <- "1"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Last Position"] <- "99"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Second Position"] <- "2"
levels(broadcasting_data$position_in_break ) #to use


####create df for tables
broadtabledf <- broadcasting_data
####drop categories after top 5 for broadcast_data
library(tidyverse)
broadtabledf$program_category_before <- fct_lump_n(broadtabledf$program_category_before, n = 5)
broadtabledf$program_category_after <- fct_lump_n(broadtabledf$program_category_after, n = 5)
broadtabledf$position_in_break <- fct_lump_n(broadtabledf$position_in_break, n = 5)
##create tables
library(table1)
table1::table1(~position_in_break + length_of_spot + program_category_before + program_category_after | country, data = broadtabledf, topclass="Rtable1-zebra")
table1::table1(~visits_index + medium + visit_source + page_category | country, data = traffic_data, topclass="Rtable1-zebra")

##### merge for belgium with data.table package
BEtraffic2 <- as.data.table(BEtraffic)
BEbroad2 <- as.data.table(BEbroad)
library(data.table)
setkey(BEtraffic2, "date_time")
setkey(BEbroad2, "date_time")
two_minutes <- 2
BEcombined <- BEbroad2[BEtraffic2, roll = +two_minutes]



###average of index
BEbroadtest$twominbefore <- sapply(BEbroadtest$dateandtime, 
                                   function(x){ mean(BEtraffictest$visits_index[(x >= BEtraffictest$date_time) & (x - 600 <=BEtraffictest$date_time)])})

BEbroadtest$twominafter <- sapply(BEbroadtest$dateandtime, 
                                  function(x){ mean(BEtraffictest$visits_index[(x <= BEtraffictest$date_time) & (x + 600 >=BEtraffictest$date_time)])})

###find average index
BEbroadtest$avgbefore <- sapply(BEbroadtest$dateandtime, 
                                function(x){ BEbroadtest$twominbefore/sum(BEtraffictest$visits_index[(x >= BEtraffictest$date_time) & (x - 600 <=BEtraffictest$date_time)]) })

BEbroadtest$avgafter <- sapply(BEbroadtest$dateandtime, 
                               function(x){ BEbroadtest$twominafter/sum(BEtraffictest$visits_index[(x <= BEtraffictest$date_time) & (x + 600 >=BEtraffictest$date_time)]) })

BEbroadtest$ad_effect <- BEbroadtest$twominafter - BEbroadtest$twominbefore


#####



########adams SQL
---
title: "TEST"
author: "Adam Kinser"
date: "1/29/2021"
output: html_document
---
```{r}
broadcasting_data6 <- broadcasting_data
broadcasting_data6$dateandtime <- as.POSIXct(paste(broadcasting_data$date, broadcasting_data$time), format="%Y-%m-%d %H:%M:%S")
broadcasting_data6 <- broadcasting_data6 [,-3] # use this 2 times please to delete date and time old colmns
NLtrafficSQL <- NLtraffic
NLbroadSQL <- NLbroad
```

```{r setup, include=FALSE}

library(RSQLite) # use this package to create a temporary SQL database on your computer
library(DBI) # use this to write SQL chunks and write to your temporary database (DB)

db <- dbConnect(RSQLite::SQLite(), ":memory:") # store the db in your memory

knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_chunk$set(connection = "db") # set you db connection for the rmarkdown


table_ad_data <- Id(table = "ad_data") # name your ad data SQL table

DBI::dbWriteTable(conn = db, # database 
                  name = table_ad_data, # name of your table
                  value = NLbroad[], # what you are loading into the table
                  overwrite = T) # overwrite option will replace the data in the current ad_data table with the new load value. You can remove `overwrite` and use `append` if you want the new value to be added to existing data.

table_traffic <- Id(table = "traffic_data") 

DBI::dbWriteTable(conn = db,
                  name = table_traffic,
                  value = NLtraffic[],
                  overwrite = T)

```

# SQL code that you can add

After adding your R chunk be sure to change the `r` to `sql` in order write SQL. 

### Check first load
```{sql, connection = db}

select * from ad_data

```

### Check second load

Note: I have to wrap `Sepal.Length` with `` because it has a '.' in the column name. If you don't do this you will get an error. 
```{sql, connection = db}

select * from traffic_data join ad_data on date_time <= dateandtime

```

### Perform the join with datetime

In the below example I use cars column (speed) to represent your ad datetime and the iris column (Sepal.Length) to represent your traffic datetime. Be sure to add the `output.var` if you want to then use that data as a dataframe in the rest of the Rmarkdown. 
```{sql, connection = db, output.var = "combined2"}

SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index)
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime

```


```{r}
combined2
```


```{sql, connection = db, output.var = "NLSQL"}
WITH NL as 
(SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index) as indexmean
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime)


SELECT * FROM ad_data da INNER JOIN NL data
ON da.dateandtime=data.ad 

```

#######adams SQL





################Netherlands ###################################
library('fastDummies')
data.5 <- NLbroadtest
str(data.5)
data.5$position_in_break <- as.factor(data.5$position_in_break) 
#dummy for data 5 
data.5 <- dummy_cols(NLbroadtest, select_columns = c('operator', 'channel', 
                                                      'program_before', 'program_after',
                                                      'program_category_before', 'program_category_after', 
                                                      'product_category', 'position_in_break', 'length_of_spot'), remove_selected_columns = TRUE)


data.5 <- data.5[-3] #erase country, dateandtime, twominsbefore, twominsafter
data.5 <- data.5[-2] #erase the country 
linearNL_in2 <- lm(data.5$ad_effect ~ data.5$`operator_Ad Alliance`+data.5$operator_Ster
                   +data.5$channel_24Kitchen+data.5$`channel_BBC First Holland`
                   +data.5$`channel_Comedy Central`+data.5$`channel_Discovery Channel`+data.5$channel_Eurosport
                   +data.5$channel_Fox+data.5$`channel_Fox Sports 1`+data.5$`channel_Fox Sports 2`
                   +data.5$`channel_Fox Sports 3`+data.5$channel_ID+
                     +data.5$channel_MTV+data.5$`channel_National Geographic Channel`
                   +data.5$channel_Net5+data.5$channel_NPO1
                   +data.5$channel_NPO2+data.5$`channel_RTL 4`+data.5$`channel_RTL 5`+data.5$`channel_RTL 7`
                   +data.5$`channel_RTL 8`+data.5$`channel_RTL Crime`+data.5$`channel_RTL Z`
                   +data.5$`channel_SBS 6`+data.5$`channel_SBS 9`+data.5$`channel_Slam!TV`
                   +data.5$channel_Spike+data.5$channel_TV538+
                     data.5$channel_Veronica
                   +data.5$position_in_break_1+data.5$position_in_break_2+data.5$position_in_break_3
                   +data.5$position_in_break_4+data.5$position_in_break_5+data.5$position_in_break_6
                   +data.5$position_in_break_7+data.5$position_in_break_8+data.5$position_in_break_9
                   +data.5$position_in_break_10+data.5$position_in_break_11+data.5$position_in_break_12
                   +data.5$position_in_break_13+data.5$position_in_break_14+data.5$position_in_break_15
                   +data.5$position_in_break_16+data.5$position_in_break_17+data.5$position_in_break_18
                   +data.5$position_in_break_19+data.5$position_in_break_20+data.5$position_in_break_21
                   +data.5$position_in_break_22+data.5$position_in_break_23
                   +data.5$position_in_break_24+data.5$position_in_break_25+data.5$position_in_break_98
                   +data.5$gross_rating_point,data = data.5) #using levels of position in break and lenth of spot
summary(linearNL_in2)



######Belgium 5 min 
linear54 <- lm(ad_effect ~ gross_rating_point
               + `program_before_ZELF JE PLAT DAK BOUWEN`
               + `program_before_WE LOVE MUSIC VIDEOS`
               + `program_before_THIS MEANS WAR`
               + `program_before_THE HANGOVER PART III`
               + `program_before_THE BIG BANG THEORY`
               + `program_before_STONEHENGE DECODED`
               + `program_before_SOFIE IN DE KEUKEN VAN...`
               + `program_before_SALVAGE HUNTERS, BEST BUYS`
               + `program_before_RELIC HUNTER`
               + `program_before_PEOPLE MAGAZINE INVESTIGATES`
               + `program_before_NO ESCAPE`
               + `program_before_MY 3000 LB FAMILY`
               + `program_before_HOW TO LOSE WEIGHT WELL`
               + `program_before_HET WEER` 
               + program_before_GETAWAY
               + `program_before_GET SANTA`
               + program_before_FAMILIE
               + `program_before_EEN FRISSE START MET VTWONEN`
               + `program_before_DE STERRENKAART`
               + `program_before_DE MOL`
               + `program_before_BRITAIN'S GOT TALENT`
               + `program_before_BLIND GEKOCHT`
               + `program_before_ALLO 'ALLO!`
               + `program_before_ADVENTURE TIME`
               + `program_before_ACCORDING TO JIM`
               + `program_before_2 BROKE GIRLS`
               , data= BEbroad5min)
summary(linear54)
##########



## Stepwise Regression 
FitAll <- lm(ad_effect1~.,data = BEbroadtest)
FitStart <- lm(ad_effect1~1,data= BEbroadtest)
step(FitStart,direction = "both" ,scope = formula(FitAll))

#output from stepwise regression for 1 minute time window
stepoutput<- lm(ad_effect1~gross_rating_point
                + `program_before_GET SANTA` 
                + `program_before_THE HANGOVER PART III` 
                + `program_before_BAKE OFF VLAANDEREN` 
                + `program_before_FALSE FLAG` 
                + `program_before_HOLLAND-BELGIE` 
                +  `program_before_INFOMERCIAL` 
                + `program_before_BLIND GEKOCHT` 
                +  `program_before_POORT AUTOMATISEREN` 
                + `program_before_LIFE IN PIECES` 
                + `program_before_THOR, THE DARK WORLD` 
                + `program_before_EEN FRISSE START MET VTWONEN` 
                + `program_before_OCEAN'S THIRTEEN` 
                + `program_before_KEVIN CAN WAIT` 
                + `program_before_RISING TOP 15` 
                + `program_before_POP STAR` 
                + `program_before_FLIP OR FLOP`
                + `program_before_THROWBACK THURSDAY` 
                +  `program_before_FLODDER` 
                + `program_before_WEEKEND VIBES` 
                + `program_before_MATCHING CHAMPIONS` 
                + `program_before_MY 3000 LB FAMILY` 
                + `program_before_8 SIMPLE RULES... FOR DATING MY TEENAGE DAUGHTER`
                + `program_before_GOD CODE` 
                + `program_before_HUMO'S COMEDY CUP`
                + `program_before_HAMILTON'S PHARMACOPEIA` 
                + `program_before_MURDER, SHE WROTE` 
                + `program_before_CASTLE` 
                + `program_before_OWN THE NIGHT` 
                + `program_before_LOVE AT FIRST KISS`
                + `program_before_ZO MAN, ZO VROUW` 
                + `program_before_STORAGE HUNTERS` 
                + `program_before_FAME` 
                + `program_before_E.R` 
                + `program_before_ZELF JE PLAT DAK BOUWEN` 
                + `program_before_GOOD BONES` 
                + `program_before_UNEXPECTED TELL ALL` 
                + `program_before_DE STERRENKAART` 
                + `program_before_THE CAPTIVE` 
                + `program_before_SUPERCAR MEGABUILD` 
                + `program_before_AMERICAN BOYBAND` 
                + `channel_SPIKE` 
                + `program_before_HITLER, THE DEFINITIVE GUIDE` 
                + `program_before_TWILIGHT` 
                + `channel_Q2` 
                + `program_before_LAST KNIGHTS` 
                + `program_before_MEISJE VAN PLEZIER` 
                + `position_in_break_2`
                + `program_before_PYTHON HUNTERS` 
                + `program_before_DE KOTMADAM` 
                + `program_before_ATLANTA` 
                + `program_before_BE COOL` 
                + `program_before_TOMMY TELESHOPPING` 
                + `program_before_K&P, KEY AND PEELE` 
                + `program_before_DE DAG` 
                + `program_before_ENFUSION LIVE` 
                + `program_before_HELDEN VAN HIER, DOOR HET VUUR` 
                + `program_before_ALLO 'ALLO!` 
                + `program_before_Z NIEUWS` 
                + `program_before_CSI NY` 
                + `program_before_THE LAST KINGDOM` 
                + `program_before_LOCKDOWN` 
                + `program_before_MY SUPER EX-GIRLFRIEND` 
                + `program_before_KOMEN ETEN` 
                + `program_before_STONEHENGE DECODED` 
                + `program_before_WW2, TREASURE HUNTERS` 
                + `program_before_HART OF DIXIE` 
                + `program_before_WE LOVE MUSIC VIDEOS` 
                + `program_before_FLESSENHOUDER MAKEN` 
                + `program_before_EMPIRE` 
                + `program_before_NAVY NCIS` 
                + `program_before_HIPPOTV SPORT` 
                + `program_before_UEFA CHAMPIONS LEAGUE` 
                + `program_before_NUANCES` 
                + `program_before_JUPITER ASCENDING` 
                + `program_before_WERKBANK MAKEN` 
                + `program_before_COLD CASE` 
                + `program_before_LAW & ORDER` 
                + `program_before_LUNCH BOX` 
                + `program_before_FAROEK` 
                + `program_before_MUNCHIES GUIDE TO` 
                + `program_before_XITE YEAR MIX` 
                + `program_before_FLIGHT` 
                + `program_before_PIXELS` 
                + `program_before_DRAIN THE OCEANS` 
                + `program_before_CODE 37` 
                + `program_before_EXTREEM JALOERS` 
                + `program_before_HOW IT'S MADE` 
                + `program_before_THE ISLAND WITH BEAR GRYLLS` 
                + `program_before_ADVENTURE TIME` 
                + `program_before_TEACHERS` 
                + `channel_COMEDY CENTRAL` 
                + `program_before_MILLION DOLLAR LISTING` 
                + `program_before_STORAGE WARS` 
                + `program_before_9-1-2001` 
                + `program_before_TUINPAD IN NATUURSTEEN` 
                + `program_before_RISEN` 
                + `program_before_THAT 70'S SHOW` 
                + `program_before_THE TAKING OF PELHAM 123` 
                + `program_before_RICK & MORTY` 
                + `program_before_DE TIP` 
                + `program_before_X-MEN, APOCALYPSE` 
                + `program_before_WETSDOKTERS` 
                + `program_before_RIDICULOUSNESS` 
                + `program_before_DE ALPEN` 
                + `program_before_STORAGE WARS CANADA` 
                + `program_before_FIXER UPPER` 
                + `program_before_THE INCREDIBLE DR. POL` 
                + `program_before_WILL & GRACE` 
                + `program_before_NASHVILLE` 
                + `program_before_SEVEN YEAR SWITCH` 
                + `program_before_HOW DO THEY DO IT?` 
                + `program_before_MY LOTTERY DREAM HOME` 
                + `program_before_EXPEDITION UNKNOWN` 
                + `program_before_CODE BLACK` 
                + `program_before_JUST TATTOO OF US` + `program_before_SHADES OF BLUE` , data=BEbroadtest)
		

##end of stepwise regression

#####convert time chr column to time and then to morning, afternoon, evening and night
broadtimebins <- broadcasting_data
broadtimebins$time <- as.POSIXct(broadtimebins$time,format="%H:%M:%S")

x=as.POSIXct(strptime(c("060000","115959","120000","175959","180000",
                        "235959"),"%H%M%S"))
library(tidyverse)
broadtimebins$time <- case_when(
  between(broadtimebins$time,x[1],x[2]) ~"morning",
  between(broadtimebins$time,x[3],x[4]) ~"afternoon",
  between(broadtimebins$time,x[5],x[6]) ~"evening",
  TRUE ~"night")
#####end of converting time chr column to time and then to morning, afternoon, evening and night



########################Belgium 10 mins #######################
library(tidyverse)
library(ggplot2)
library(dplyr)
library('fastDummies')
library(Boruta) 

traffic_data_in<- read.csv("C:/Users/kzkon/Downloads/Seminar Case Studies in Data Science and/traffic_data.R")
broadcasting_data <-read.csv("C:/Users/kzkon/Downloads/Seminar Case Studies in Data Science and/broadcasting_data.R")


#eliminate bounce variable
traffic_data <- traffic_data_in[-7]
#converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                       mean(avg_session_quality, na.rm = TRUE), avg_session_quality))
#convert into dates -
traffic_data$date_time <- as.POSIXct(traffic_data$date_time) # - this might take a while
#factorize all the variables 
traffic_data$medium <- as.factor(traffic_data$medium)
traffic_data$visit_source <- as.factor(traffic_data$visit_source)
traffic_data$page_category<-as.factor(traffic_data$page_category)
traffic_data$country<- as.factor(traffic_data$country)

#divide the countries. 

bel_traffic <- traffic_data %>% 
  filter(country=="Belgium")

#now that we divide the datasets , "country" variable must go 

bel_traffic <- bel_traffic[-7]

#now lets deal with the broadcasting data 
broadcasting_data$operator <- as.factor(broadcasting_data$operator)
broadcasting_data$channel <- as.factor(broadcasting_data$channel)
broadcasting_data$length_of_spot <- as.factor(broadcasting_data$length_of_spot)
broadcasting_data$program_before <- as.factor(broadcasting_data$program_before)
broadcasting_data$program_after <- as.factor(broadcasting_data$program_after)
broadcasting_data$program_category_before <- as.factor(broadcasting_data$program_category_before)
broadcasting_data$program_category_after <- as.factor(broadcasting_data$program_category_after)
broadcasting_data$product_category <- as.factor(broadcasting_data$product_category)
broadcasting_data$country <- as.factor(broadcasting_data$country)

#we dividing broadcasting data by country 

bel_broad <- broadcasting_data %>% 
  filter(country == "Belgium")
#erasing the "country" column from each 
bel_broad <- bel_broad[-13]


#converting date and time into seconds from origin time(1970) for both countries - traffic data  
bel_traffic$date_time <- as.numeric(bel_traffic$date_time)


#converting date and time into seconds from origin time(1970) for both countries - traffic data  - belgium

bel_broad$dateandtime <- as.POSIXct(paste(bel_broad$date, bel_broad$time), 
                                    format="%Y-%m-%d %H:%M:%S") #create seperate columns for date and time 
bel_broad$dateandtime <- as.numeric(bel_broad$dateandtime)

#now I have to delete the old columns of broadcasting data of "date" & "time"

bel_broad <- bel_broad[-(3:4)]
#now bel_broad  have 11 variables 
bel_broad$dateandtime

#Belgium
bel_broad$tenminbefore <- sapply(bel_broad$dateandtime, 
                                  function(x){ sum(bel_traffic$visits_index[
                                    (x >= bel_traffic$date_time) & 
                                      (x - 600 <=bel_traffic$date_time)])}) #- it's going to take some time

bel_broad$tenminafter <- sapply(bel_broad$dateandtime, 
                                 function(x){ sum(bel_traffic$visits_index[
                                   (x <= bel_traffic$date_time) & 
                                     (x + 600 >= bel_traffic$date_time)])})#- it's going to take some time


#now that you created the two variables I am going to take the difference of it
bel_broad$ad_effect <- bel_broad$tenminafter - bel_broad$tenminbefore


#create dummies to run lm with interactions 

#create a duplicate dataset 
bel_broad1 <- bel_broad
time_bel <- bel_broad$dateandtime #keep date and time at a vector 
bel_broad1 <- bel_broad1[,-(11:13)] #from the new created variables we only keep the ad_effect
names(bel_broad1)
#now working with the neth_broad1
#create dummies for the regression
#No.2 without bothering the program before,program after, program category before and program category
bel_broad2 <- dummy_cols(bel_broad1, select_columns = c('operator', 'channel', 'product_category', 
                                                          'position_in_break', 'length_of_spot'), remove_selected_columns = TRUE)
#No.3 including bothering the program before,program after, program category before and program category
bel_broad3 <- dummy_cols(bel_broad1, select_columns = c('operator', 'channel', 
                                                          'program_before', 'program_after',
                                                          'program_category_before', 'program_category_after', 
                                                          'product_category', 'position_in_break', 'length_of_spot'), remove_selected_columns = TRUE)


bel_broad3 <- bel_broad3[,which(colSums(bel_broad3) !=0)]

### Stepwise Regression 
FitAll <- lm(ad_effect~.,data = bel_broad3)
FitStart <- lm(ad_effect~1,data= bel_broad3)
step <- step(FitStart,direction = "both" ,scope = formula(FitAll))
summary(step)
s
hortlistedVars <- names(unlist(step[[1]])) # get the shortlisted variable.
shortlistedVars <- shortlistedVars[!shortlistedVars %in% "(Intercept)"] # remove intercept


####end of Belgium 10 mins####

#####Plots

#Plots for Interpretations ! Good but unreadable
library(tidyverse)
library(tidymodels)

#stepout is the name of the lm model . -1 is used for the intercept to be eliminated.


stepoutput%>%
  tidy()%>%
  slice(-1)%>%
  ggplot(aes(x=term, y= estimate)) +
  geom_point() +
  coord_flip()


stepoutput%>%
  tidy()%>%
  slice(-1)%>%
  mutate(pos_neg= if_else(estimate<= 0, "Negative","Positive"))%>%
  ggplot(aes(x=term, y= estimate, color= pos_neg)) +
  geom_boxplot() +
  coord_flip()

#########plot vector of coefs from a regression
library(jtools)
plot_summs(BElm, coefs = c("gross_rating_point", "program_before_THE.HANGOVER.PART.III", 
                                      "channel_SPIKE", "program_category_before_debate.talk.show"), scale = TRUE, ci_level = 0.99)
#######end of plotting coefs













