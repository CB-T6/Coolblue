#Coolblue

#Check for missing values 
apply(is.na(broadcasting_data[,]),2,sum) 
apply(is.na(traffic_data[,]),2,sum) # average session: 13,5% of missing values & 
                                    # bounces :49% of missing values . We delete variable "bounces"
                                              
#Converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))                                 
                        
#Deleting "bounces"
traffic_data <- subset(traffic_data, select = -c(bounces))
summary(traffic_data)                                   
                                   
#Convert into dates/time
traffic_data$date_time <- as.POSIXct(traffic_data$date_time)
broadcasting_data$date <- as.POSIXct(broadcasting_data$date)

#Factorize
traffic_data$medium <- as.factor(traffic_data$medium)
traffic_data$visit_source <- as.factor(traffic_data$visit_source)
traffic_data$page_category<-as.factor(traffic_data$page_category)
traffic_data$country<-as.factor(traffic_data$country)
broadcasting_data$operator <- as.factor(broadcasting_data$operator)
broadcasting_data$channel <- as.factor(broadcasting_data$channel)
broadcasting_data$position_in_break <- as.factor(broadcasting_data$position_in_break)
broadcasting_data$length_of_spot <- as.factor(broadcasting_data$length_of_spot)
broadcasting_data$program_before <- as.factor(broadcasting_data$program_before)
broadcasting_data$program_after <- as.factor(broadcasting_data$program_after)
broadcasting_data$program_category_before <- as.factor(broadcasting_data$program_category_before)
broadcasting_data$program_category_after <- as.factor(broadcasting_data$program_category_after)
broadcasting_data$product_category <- as.factor(broadcasting_data$product_category)
broadcasting_data$country <- as.factor(broadcasting_data$country)
 

#cleanup first
updated_traffic <- subset(traffic_data, visit_source!= "push notification")
traffic_data <- subset(updated_traffic, visit_source!= "other")

#Check for outliers
boxplot(broadcasting_data$gross_rating_point,xlab ="gross_rating_point")          # many  outliers, not gonna delete them, important for analysis
boxplot(traffic_data$avg_session_quality,xlab ="avg_session_quality")


#Descriptive Statistics
library(psych)
describe(broadcasting_data)
describe(traffic_data$avg_session_quality)
describe(traffic_data$visits_index)
                            

#find the mean 
mean(traffic_data$avg_session_quality, na.rm = TRUE)
apply(is.na(traffic_data[,]),2,sum) 
mean(traffic_data$avg_session_quality, na.rm = TRUE )


#converting NAs to mean
traffic_data <- traffic_data  %>% 
  mutate(avg_session_quality = if_else(is.na(avg_session_quality) == TRUE, 
                                 mean(avg_session_quality, na.rm = TRUE), avg_session_quality))


#data exploration 
#Mean and variance for two numeric variables
traffic_data %>%
  summarise(median=median(avg_session_quality), variance=var(avg_session_quality))


traffic_data %>%
  summarise(median=median(visits_index), variance=var(visits_index))

traffic_data %>%
  summarise(mean=mean(visits_index), variance=var(visits_index))



range(traffic_data$visits_index)

min(traffic_data$avg_session_quality) #1
max(traffic_data$avg_session_quality) #96



(country_separation1 <- traffic_data %>%
  group_by(country) %>% 
  summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #useful

(country_separation2 <- traffic_data %>%
    group_by(country) %>% 
    summarise(mean=mean(visits_index), variance=var(visits_index))) #useful


#for now not helping, future?
(country_separation3 <- traffic_data %>%
    group_by(date_time) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

(country_separation3 <- traffic_data %>%
    group_by(date_time, country) %>% 
    summarise(mean=mean(avg_session_quality), variance=var(avg_session_quality))) #notuseful

table(traffic_data$medium, traffic_data$country)/length(traffic_data$medium)
table(traffic_data$page_category)/length(traffic_data$page_category)            
table(traffic_data$page_category, traffic_data$country) / length(traffic_data$country)          

#numeric variables
range(traffic_data$avg_session_quality)
range(traffic_data$visits_index) #maybe

#corr - must be numeric
cor(traffic_data$avg_session_quality, traffic_data$visits_index) #-0.005074682
cov(traffic_data$avg_session_quality, traffic_data$visits_index) #=variance, -0.001598219


plot(traffic_data$avg_session_quality, traffic_data$visits_index)

                                  
                                  
                                  
#DATA EXPLORATION FOR BROADCASTING 
plot(broadcasting_data$position_in_break, broadcasting_data$length_of_spot)
plot(broadcasting_data$gross_rating_point, broadcasting_data$position_in_break)

levels(broadcasting_data$position_in_break ) #to use


table(broadcasting_data$length_of_spot, broadcasting_data$country )
table(broadcasting_data$position_in_break, broadcasting_data$country)

#RELEVELS
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Before Last Position"] <- "98"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Any Other Position"] <- "0"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "First Position"] <- "1"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Last Position"] <- "99"
levels(broadcasting_data$position_in_break)[levels(broadcasting_data$position_in_break) == "Second Position"] <- "2"
levels(broadcasting_data$position_in_break ) #to use


####create df for tables
broadtabledf <- broadcasting_data
####drop categories after top 5 for broadcast_data
library(tidyverse)
broadtabledf$program_category_before <- fct_lump_n(broadtabledf$program_category_before, n = 5)
broadtabledf$program_category_after <- fct_lump_n(broadtabledf$program_category_after, n = 5)
broadtabledf$position_in_break <- fct_lump_n(broadtabledf$position_in_break, n = 5)
##create tables
library(table1)
table1::table1(~position_in_break + length_of_spot + program_category_before + program_category_after | country, data = broadtabledf, topclass="Rtable1-zebra")
table1::table1(~visits_index + medium + visit_source + page_category | country, data = traffic_data, topclass="Rtable1-zebra")

##### merge for belgium with data.table package
BEtraffic2 <- as.data.table(BEtraffic)
BEbroad2 <- as.data.table(BEbroad)
library(data.table)
setkey(BEtraffic2, "date_time")
setkey(BEbroad2, "date_time")
two_minutes <- 2
BEcombined <- BEbroad2[BEtraffic2, roll = +two_minutes]



###average of index
BEbroadtest$twominbefore <- sapply(BEbroadtest$dateandtime, 
                                   function(x){ mean(BEtraffictest$visits_index[(x >= BEtraffictest$date_time) & (x - 600 <=BEtraffictest$date_time)])})

BEbroadtest$twominafter <- sapply(BEbroadtest$dateandtime, 
                                  function(x){ mean(BEtraffictest$visits_index[(x <= BEtraffictest$date_time) & (x + 600 >=BEtraffictest$date_time)])})

###find average index
BEbroadtest$avgbefore <- sapply(BEbroadtest$dateandtime, 
                                function(x){ BEbroadtest$twominbefore/sum(BEtraffictest$visits_index[(x >= BEtraffictest$date_time) & (x - 600 <=BEtraffictest$date_time)]) })

BEbroadtest$avgafter <- sapply(BEbroadtest$dateandtime, 
                               function(x){ BEbroadtest$twominafter/sum(BEtraffictest$visits_index[(x <= BEtraffictest$date_time) & (x + 600 >=BEtraffictest$date_time)]) })

BEbroadtest$ad_effect <- BEbroadtest$twominafter - BEbroadtest$twominbefore


#####



########adams SQL
---
title: "TEST"
author: "Adam Kinser"
date: "1/29/2021"
output: html_document
---
```{r}
broadcasting_data6 <- broadcasting_data
broadcasting_data6$dateandtime <- as.POSIXct(paste(broadcasting_data$date, broadcasting_data$time), format="%Y-%m-%d %H:%M:%S")
broadcasting_data6 <- broadcasting_data6 [,-3] # use this 2 times please to delete date and time old colmns
NLtrafficSQL <- NLtraffic
NLbroadSQL <- NLbroad
```

```{r setup, include=FALSE}

library(RSQLite) # use this package to create a temporary SQL database on your computer
library(DBI) # use this to write SQL chunks and write to your temporary database (DB)

db <- dbConnect(RSQLite::SQLite(), ":memory:") # store the db in your memory

knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_chunk$set(connection = "db") # set you db connection for the rmarkdown


table_ad_data <- Id(table = "ad_data") # name your ad data SQL table

DBI::dbWriteTable(conn = db, # database 
                  name = table_ad_data, # name of your table
                  value = NLbroad[], # what you are loading into the table
                  overwrite = T) # overwrite option will replace the data in the current ad_data table with the new load value. You can remove `overwrite` and use `append` if you want the new value to be added to existing data.

table_traffic <- Id(table = "traffic_data") 

DBI::dbWriteTable(conn = db,
                  name = table_traffic,
                  value = NLtraffic[],
                  overwrite = T)

```

# SQL code that you can add

After adding your R chunk be sure to change the `r` to `sql` in order write SQL. 

### Check first load
```{sql, connection = db}

select * from ad_data

```

### Check second load

Note: I have to wrap `Sepal.Length` with `` because it has a '.' in the column name. If you don't do this you will get an error. 
```{sql, connection = db}

select * from traffic_data join ad_data on date_time <= dateandtime

```

### Perform the join with datetime

In the below example I use cars column (speed) to represent your ad datetime and the iris column (Sepal.Length) to represent your traffic datetime. Be sure to add the `output.var` if you want to then use that data as a dataframe in the rest of the Rmarkdown. 
```{sql, connection = db, output.var = "combined2"}

SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index)
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime

```


```{r}
combined2
```


```{sql, connection = db, output.var = "NLSQL"}
WITH NL as 
(SELECT 
	ad.dateandtime as ad
,	COUNT(date_time) as traffic
, SUM(visits_index)/COUNT(tr.visits_index) as indexmean
FROM ad_data ad
LEFT JOIN traffic_data tr
		ON tr.date_time BETWEEN ad.dateandtime and (ad.dateandtime + 120)
GROUP BY ad.dateandtime)


SELECT * FROM ad_data da INNER JOIN NL data
ON da.dateandtime=data.ad 

```

#######adams SQL





################Netherlands ###################################
library('fastDummies')
data.5 <- NLbroadtest
str(data.5)
data.5$position_in_break <- as.factor(data.5$position_in_break) 
#dummy for data 5 
data.5 <- dummy_cols(NLbroadtest, select_columns = c('operator', 'channel', 
                                                      'program_before', 'program_after',
                                                      'program_category_before', 'program_category_after', 
                                                      'product_category', 'position_in_break', 'length_of_spot'), remove_selected_columns = TRUE)


data.5 <- data.5[-3] #erase country, dateandtime, twominsbefore, twominsafter
data.5 <- data.5[-2] #erase the country 
linearNL_in2 <- lm(data.5$ad_effect ~ data.5$`operator_Ad Alliance`+data.5$operator_Ster
                   +data.5$channel_24Kitchen+data.5$`channel_BBC First Holland`
                   +data.5$`channel_Comedy Central`+data.5$`channel_Discovery Channel`+data.5$channel_Eurosport
                   +data.5$channel_Fox+data.5$`channel_Fox Sports 1`+data.5$`channel_Fox Sports 2`
                   +data.5$`channel_Fox Sports 3`+data.5$channel_ID+
                     +data.5$channel_MTV+data.5$`channel_National Geographic Channel`
                   +data.5$channel_Net5+data.5$channel_NPO1
                   +data.5$channel_NPO2+data.5$`channel_RTL 4`+data.5$`channel_RTL 5`+data.5$`channel_RTL 7`
                   +data.5$`channel_RTL 8`+data.5$`channel_RTL Crime`+data.5$`channel_RTL Z`
                   +data.5$`channel_SBS 6`+data.5$`channel_SBS 9`+data.5$`channel_Slam!TV`
                   +data.5$channel_Spike+data.5$channel_TV538+
                     data.5$channel_Veronica
                   +data.5$position_in_break_1+data.5$position_in_break_2+data.5$position_in_break_3
                   +data.5$position_in_break_4+data.5$position_in_break_5+data.5$position_in_break_6
                   +data.5$position_in_break_7+data.5$position_in_break_8+data.5$position_in_break_9
                   +data.5$position_in_break_10+data.5$position_in_break_11+data.5$position_in_break_12
                   +data.5$position_in_break_13+data.5$position_in_break_14+data.5$position_in_break_15
                   +data.5$position_in_break_16+data.5$position_in_break_17+data.5$position_in_break_18
                   +data.5$position_in_break_19+data.5$position_in_break_20+data.5$position_in_break_21
                   +data.5$position_in_break_22+data.5$position_in_break_23
                   +data.5$position_in_break_24+data.5$position_in_break_25+data.5$position_in_break_98
                   +data.5$gross_rating_point,data = data.5) #using levels of position in break and lenth of spot
summary(linearNL_in2)




















